---
title: "STAT 452 Fall 24: Lab 4"
format: html
author: Your Name
---


```{r setup}
#| message: false
library(tidyverse)
```


In this lab we will use the classical variable selection methods 
we covered last week to identify a good prediction model for some MLB data.


To complete this lab you will need to first need to access data which
is included in the `Lahman` R package. After you have installed that
package the following code will process some of this data.

```{r}

library(Lahman)


model_data <- as_tibble(Teams) |> 
  filter(yearID > 1999) |> 
  select(W, L, R:FP) |> 
  mutate(win_pct = W/(W + L)) |> 
  select(win_pct, R:FP)

```


Here the final data consists MLB team summary statistics since the 2000
season. The response we want to predict is the win percentage and 
we have 26 variables describing team batting pitching and fielding statistics.


## Exercise 1


As we have a large number of predictors here we cannot do all subsets 
selection. 
Fit forward stepwise selection with this data. To do this:

- Split the data into a 75% training set (`data_train`) and
a 25% validation set (`data_valid`).
- Fit two models, one using the AIC penalty and one using the BIC penalty.
- For the simplest model consider only the intercept term, so `Y ~ 1.`
- For the most complex model allow any pairwise interactions of the predictors.
You can do this using the model formula `Y ~ .^2` in `lm`.
- Use the fitted model from each to predict on the validation set and compute
the MSPE. The following function from last week 
may be useful.


- Does the choice of AIC or BIC lead to different numbers of predictors
being used? Is the result surprising?


- If you know anything about Baseball, do the chosen predictors make sense?

Note that the option `trace=0` in the `step` function avoids it printing
all the models it fits. This may be helpful here, when there are many 
predictors.

```{r}
get_MSPE <- function(Y, Y_hat) {
  residuals <- Y - Y_hat
  resid_sq <- residuals^2
  SSPE <- sum(resid_sq)
  MSPE <- SSPE / length(Y)
  return(MSPE)
}
```



```{r}

```



## Exercise 2

Now repeat the above procedure using 10-fold CV on the __entire dataset__.


Note that this code might take a little while (a minute or two) 
to run.

Create a boxplot of the estimated MSPEs and also the relative MSPEs.
Which penalty would you prefer, based on these plots?


```{r}


```

